---
title: Accelerate PyTorch models
parent: Tutorials
nav_order: 3
---
# Accelerate PyTorch models
{: .no_toc }

ONNX Runtime can help accelerate PyTorch models in both training and inferencing tasks.

## Contents
{: .no_toc }

* TOC placeholder
{:toc}

## Convert model to ONNX

* [torch.onnx full documentation and samples](https://pytorch.org/docs/stable/onnx.html)
* [Export PyTorch model with custom ops](./export-pytorch-model.md)

## Accelerate PyTorch model inferencing

* [Inference: accelerate reduced size BERT model through quantization](https://github.com/microsoft/onnxruntime/blob/master/onnxruntime/python/tools/quantization/notebooks/Bert-GLUE_OnnxRuntime_quantization.ipynb)

## Accelerate PyTorch model training

* [Training: accelerate pre-training of large BERT model](https://github.com/microsoft/onnxruntime-training-examples/tree/master/nvidia-bert)