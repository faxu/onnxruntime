---
title: Deploy on mobile
has_children: false
grand_parent: Tutorials
parent: Inferencing
nav_order: 5
---
# Deploy ML models on mobile devices
ONNX Runtime can be used to performantly deploy models on mobile devices. Learn more about the mobile build and optimizations under [Build ORT for mobile](../../how-to/mobile.html).

* *[COMING SOON]* Small and fast model inferencing on Android
* *[COMING SOON]* Small and fast model inferencing on iOS
